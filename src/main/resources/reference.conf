kafka4m {

  # when run as an 'app' (e.g. the Kafka4mApp), this value should be 'read' or 'write'
  action: ""

  # The kafka topic from which we'll read/write to
  topic: ""

  # The default boostrap server(s) to connect to
  bootstrap.servers: "localhost:9092"

  # an admin client
  admin.topic = ${kafka4m.topic}
  admin.bootstrap.servers = ${kafka4m.bootstrap.servers}

  # the 'producer' configuration is used to push to kafka
  producer.topic = ${kafka4m.topic}
  producer.bootstrap.servers = ${kafka4m.bootstrap.servers}
  producer.fireAndForget: false
  producer.key.serializer: "org.apache.kafka.common.serialization.StringSerializer"
  producer.value.serializer: "org.apache.kafka.common.serialization.ByteArraySerializer"

  # the amount of time to wait for data to arrive from kafka
  consumer {
    topic = ${kafka4m.topic}
    bootstrap.servers = ${kafka4m.bootstrap.servers}

    max.poll.records: 1024
    max.poll.interval.ms: 5000

    # used by the KafkaConsumerFeed to determine the queue size for data pulled into the kafka consumer
    commandQueueSize: 100

    pollTimeout: "500ms"
    feedTimeout: "1m"
    group.id: "kafka4m-consumer"
    auto.offset.reset: earliest
  }

  # the 'streams' configuration is used for reading from Kafka
  streams {
    topic = ${kafka4m.topic}
    bootstrap.servers = ${kafka4m.bootstrap.servers}

    application.id: "kafka4m-app"
    default.key.serde: "org.apache.kafka.common.serialization.Serdes$StringSerde"
    default.value.serde: "org.apache.kafka.common.serialization.Serdes$ByteArraySerde"
    auto.offset.reset: earliest
  }
}